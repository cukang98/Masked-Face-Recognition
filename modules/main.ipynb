{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask Detection - VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories=['train','test']\n",
    "categories1=['without_mask','with_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=[]\n",
    "for category in categories1:\n",
    "    path=os.path.join('dataset\\mask_detection',category)\n",
    "    label1=categories1.index(category)\n",
    "    for file in os.listdir(path):\n",
    "       img_path=os.path.join(path,file)\n",
    "       img=cv2.imread(img_path)\n",
    "       img=cv2.resize(img,(224,224))\n",
    "       data1.append([img,label1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.18039216, 0.19607843, 0.18823529],\n",
       "        [0.1372549 , 0.14901961, 0.14117647],\n",
       "        [0.10196078, 0.10980392, 0.10980392],\n",
       "        ...,\n",
       "        [0.09803922, 0.1372549 , 0.16470588],\n",
       "        [0.07058824, 0.10980392, 0.1372549 ],\n",
       "        [0.08627451, 0.1254902 , 0.15686275]],\n",
       "\n",
       "       [[0.13333333, 0.14509804, 0.1372549 ],\n",
       "        [0.08627451, 0.10196078, 0.09411765],\n",
       "        [0.12941176, 0.1372549 , 0.1372549 ],\n",
       "        ...,\n",
       "        [0.07058824, 0.10980392, 0.13333333],\n",
       "        [0.10196078, 0.14117647, 0.16470588],\n",
       "        [0.06666667, 0.10196078, 0.12941176]],\n",
       "\n",
       "       [[0.09411765, 0.10588235, 0.09803922],\n",
       "        [0.09411765, 0.10588235, 0.09803922],\n",
       "        [0.13333333, 0.14117647, 0.14117647],\n",
       "        ...,\n",
       "        [0.05098039, 0.08627451, 0.10588235],\n",
       "        [0.09411765, 0.1254902 , 0.15294118],\n",
       "        [0.10980392, 0.14117647, 0.16862745]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.09803922, 0.08235294, 0.0627451 ],\n",
       "        [0.09411765, 0.07843137, 0.05882353],\n",
       "        [0.08627451, 0.0745098 , 0.05490196],\n",
       "        ...,\n",
       "        [0.34509804, 0.53333333, 0.65882353],\n",
       "        [0.34509804, 0.5372549 , 0.67058824],\n",
       "        [0.35294118, 0.54117647, 0.6745098 ]],\n",
       "\n",
       "       [[0.09411765, 0.07843137, 0.05882353],\n",
       "        [0.09411765, 0.07843137, 0.05882353],\n",
       "        [0.08627451, 0.0745098 , 0.05490196],\n",
       "        ...,\n",
       "        [0.34901961, 0.54117647, 0.66666667],\n",
       "        [0.35686275, 0.54509804, 0.67843137],\n",
       "        [0.36078431, 0.54901961, 0.68235294]],\n",
       "\n",
       "       [[0.09411765, 0.07843137, 0.05882353],\n",
       "        [0.09411765, 0.07843137, 0.05882353],\n",
       "        [0.08627451, 0.0745098 , 0.05490196],\n",
       "        ...,\n",
       "        [0.34901961, 0.54117647, 0.66666667],\n",
       "        [0.34509804, 0.54509804, 0.6745098 ],\n",
       "        [0.36078431, 0.55686275, 0.69803922]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1=[]\n",
    "y1=[]\n",
    "for features1,label1 in data1:\n",
    "    x1.append(features1)\n",
    "    y1.append(label1)\n",
    "\n",
    "    \n",
    "x1=np.array(x1)\n",
    "y1=np.array(y1)\n",
    "\n",
    "\n",
    "x1=x1/255\n",
    "\n",
    "x1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection  import train_test_split\n",
    "x_train1_full,x_test1,y_train1_full,y_test1=train_test_split(x1,y1,test_size=0.2,random_state = 42)\n",
    "x_train, x_valid = x_train1_full[:-70], x_train1_full[-70:]\n",
    "y_train, y_valid = y_train1_full[:-70], y_train1_full[-70:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "282"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape\n",
    "x_valid.shape\n",
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range = 30,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.2, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip = True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "vgg=VGG16()\n",
    "for layer in vgg.layers[:-1]:\n",
    "    model.add(layer)\n",
    "    \n",
    "for layer in model.layers:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "=================================================================\n",
      "Total params: 134,260,544\n",
      "Trainable params: 0\n",
      "Non-trainable params: 134,260,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.build(x_train.shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg1=VGG16()\n",
    "vgg1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 134,264,641\n",
      "Trainable params: 4,097\n",
      "Non-trainable params: 134,260,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "earlyStopping = EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0,\n",
    "                              patience=3,\n",
    "                              verbose=1,\n",
    "                              mode='min',\n",
    "                              restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "8/8 [==============================] - 62s 8s/step - loss: 0.5791 - accuracy: 0.8160 - val_loss: 0.4263 - val_accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 64s 8s/step - loss: 0.3871 - accuracy: 0.9922 - val_loss: 0.2861 - val_accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 58s 7s/step - loss: 0.2669 - accuracy: 0.9960 - val_loss: 0.2060 - val_accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 96s 11s/step - loss: 0.2093 - accuracy: 0.9880 - val_loss: 0.1571 - val_accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 64s 8s/step - loss: 0.1581 - accuracy: 1.0000 - val_loss: 0.1184 - val_accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 60s 8s/step - loss: 0.1277 - accuracy: 1.0000 - val_loss: 0.0939 - val_accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 65s 8s/step - loss: 0.1048 - accuracy: 1.0000 - val_loss: 0.0945 - val_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 70s 9s/step - loss: 0.1032 - accuracy: 0.9880 - val_loss: 0.0678 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 64s 8s/step - loss: 0.0785 - accuracy: 1.0000 - val_loss: 0.0626 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 62s 8s/step - loss: 0.0744 - accuracy: 0.9920 - val_loss: 0.0528 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 61s 8s/step - loss: 0.0708 - accuracy: 0.9960 - val_loss: 0.0517 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 71s 9s/step - loss: 0.0617 - accuracy: 1.0000 - val_loss: 0.0454 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 75s 9s/step - loss: 0.0554 - accuracy: 1.0000 - val_loss: 0.0407 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 63s 8s/step - loss: 0.0570 - accuracy: 0.9960 - val_loss: 0.0438 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 63s 8s/step - loss: 0.0458 - accuracy: 1.0000 - val_loss: 0.0343 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 60s 8s/step - loss: 0.0462 - accuracy: 1.0000 - val_loss: 0.0315 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 61s 8s/step - loss: 0.0422 - accuracy: 1.0000 - val_loss: 0.0294 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 55s 7s/step - loss: 0.0376 - accuracy: 1.0000 - val_loss: 0.0291 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 56s 7s/step - loss: 0.0349 - accuracy: 1.0000 - val_loss: 0.0254 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 59s 8s/step - loss: 0.0364 - accuracy: 0.9960 - val_loss: 0.0274 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1da652f9400>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(datagen.flow(x_train, y_train, batch_size=32),\n",
    "         steps_per_epoch=len(x_train) // 32, epochs=20,\n",
    "         validation_data=(x_valid,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 14s - loss: 0.0436 - accuracy: 0.9888\n",
      "Trained model, accuracy: 98.88%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x_test1, y_test1, verbose=2)\n",
    "print(\"Trained model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000231608F8940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unable to locate the source code of <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000231608F8940>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000231608F8940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unable to locate the source code of <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000231608F8940>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000231608F8940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unable to locate the source code of <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000231608F8940>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, dense_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"model.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masked Face Recognition VGG16 (VGGFace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories=['train','test']\n",
    "data=[]\n",
    "cate=[]\n",
    "for category in categories:\n",
    "    path=os.path.join('dataset',category)\n",
    "    for file in os.listdir(path):\n",
    "        if not file.startswith('.'):\n",
    "            img_path=os.path.join(path,file)\n",
    "            cate.append(file)\n",
    "            label=cate.index(file)\n",
    "            files=os.listdir(img_path)\n",
    "            for i in files:\n",
    "                p=os.path.join(img_path,i)\n",
    "                img_path=os.path.join(path,file)\n",
    "                #print(p)\n",
    "                img=cv2.imread(p)\n",
    "                img=cv2.resize(img,(224,224))\n",
    "                data.append([img,label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adriana_lima', 'alex_lawther', 'amber_heard', 'ben_affleck', 'bill_gates', 'bobby_morley', 'chris_evans', 'cristiano_ronaldo', 'cukang', 'dwayne_johnson', 'elon_musk', 'emilia_clarke', 'grant_gustin', 'gwyneth_paltrow', 'jeremy_renner', 'jimmy_fallon', 'maisie_williams', 'markzuckerberg', 'mark_wahlberg', 'rihanna', 'tom_cruise', 'will_smith', 'zoe_saldana']\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "h=(int(len(cate)/2))\n",
    "del cate[:h]\n",
    "print(cate)\n",
    "print(len(cate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[]\n",
    "y=[]\n",
    "for features,label in data:\n",
    "    x.append(features)\n",
    "    y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array(x)\n",
    "y=np.array(y)\n",
    "\n",
    "x=x/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection  import train_test_split\n",
    "x_train_full,x_test,y_train_full,y_test=train_test_split(x,y,test_size=0.2,random_state = 42)\n",
    "x_train, x_valid = x_train_full[:-70], x_train_full[-70:]\n",
    "y_train, y_valid = y_train_full[:-70], y_train_full[-70:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(183, 224, 224, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range = 30,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.2, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip = True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg16=Sequential()\n",
    "vgg=VGG16()\n",
    "for layer in vgg.layers[:-1]:\n",
    "    model_vgg16.add(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_vgg16.layers:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "model_vgg16.add(Dense(len(cate),activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 23)                94231     \n",
      "=================================================================\n",
      "Total params: 134,354,775\n",
      "Trainable params: 94,231\n",
      "Non-trainable params: 134,260,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "earlyStopping = EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0,\n",
    "                              patience=5,\n",
    "                              verbose=1,\n",
    "                              mode='min',\n",
    "                              restore_best_weights = True)\n",
    "model_vgg16.compile(optimizer=optimizer,\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 [==============================] - 30s 2s/step - loss: 4.7842 - accuracy: 0.0381 - val_loss: 4.1879 - val_accuracy: 0.0571\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 34s 2s/step - loss: 4.1205 - accuracy: 0.0381 - val_loss: 3.6655 - val_accuracy: 0.0571\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 36s 3s/step - loss: 3.6534 - accuracy: 0.0571 - val_loss: 3.4514 - val_accuracy: 0.0429\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 36s 3s/step - loss: 3.5587 - accuracy: 0.0571 - val_loss: 3.7849 - val_accuracy: 0.0571\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 39s 3s/step - loss: 3.2687 - accuracy: 0.1524 - val_loss: 3.1543 - val_accuracy: 0.0714\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 36s 3s/step - loss: 3.1303 - accuracy: 0.1429 - val_loss: 3.1053 - val_accuracy: 0.1286\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 34s 3s/step - loss: 3.0403 - accuracy: 0.0952 - val_loss: 3.1622 - val_accuracy: 0.1857\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 35s 3s/step - loss: 2.7195 - accuracy: 0.2190 - val_loss: 3.2071 - val_accuracy: 0.1143\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 37s 3s/step - loss: 2.7655 - accuracy: 0.2232 - val_loss: 3.3654 - val_accuracy: 0.1857\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 38s 3s/step - loss: 2.6219 - accuracy: 0.3393 - val_loss: 2.8906 - val_accuracy: 0.1857\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 37s 3s/step - loss: 2.5616 - accuracy: 0.2095 - val_loss: 3.3144 - val_accuracy: 0.1571\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 37s 3s/step - loss: 2.5714 - accuracy: 0.2952 - val_loss: 2.7112 - val_accuracy: 0.2571\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 37s 3s/step - loss: 2.4588 - accuracy: 0.3143 - val_loss: 2.9814 - val_accuracy: 0.1571\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 38s 3s/step - loss: 2.3382 - accuracy: 0.2857 - val_loss: 2.7059 - val_accuracy: 0.1714\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 37s 3s/step - loss: 2.2212 - accuracy: 0.3333 - val_loss: 3.0426 - val_accuracy: 0.2000\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 38s 3s/step - loss: 2.7600 - accuracy: 0.2095 - val_loss: 3.0646 - val_accuracy: 0.2429\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 37s 3s/step - loss: 2.4929 - accuracy: 0.4476 - val_loss: 3.0155 - val_accuracy: 0.3000\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 36s 3s/step - loss: 2.5944 - accuracy: 0.2952 - val_loss: 3.1138 - val_accuracy: 0.1857\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 38s 3s/step - loss: 2.1185 - accuracy: 0.4095 - val_loss: 2.8321 - val_accuracy: 0.2429\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 38s 3s/step - loss: 2.1644 - accuracy: 0.3929 - val_loss: 2.6046 - val_accuracy: 0.3286\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 37s 3s/step - loss: 1.9958 - accuracy: 0.4095 - val_loss: 2.8617 - val_accuracy: 0.1571\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 37s 3s/step - loss: 1.8807 - accuracy: 0.4286 - val_loss: 2.2748 - val_accuracy: 0.3714\n",
      "Epoch 23/100\n",
      "14/14 [==============================] - 38s 3s/step - loss: 1.9853 - accuracy: 0.4476 - val_loss: 2.3992 - val_accuracy: 0.2857\n",
      "Epoch 24/100\n",
      "14/14 [==============================] - 37s 3s/step - loss: 1.7460 - accuracy: 0.4952 - val_loss: 2.6362 - val_accuracy: 0.0857\n",
      "Epoch 25/100\n",
      "14/14 [==============================] - 37s 3s/step - loss: 1.9119 - accuracy: 0.4286 - val_loss: 2.5713 - val_accuracy: 0.3571\n",
      "Epoch 26/100\n",
      "14/14 [==============================] - 38s 3s/step - loss: 1.9434 - accuracy: 0.4643 - val_loss: 3.0878 - val_accuracy: 0.3571\n",
      "Epoch 27/100\n",
      "14/14 [==============================] - 37s 3s/step - loss: 1.9757 - accuracy: 0.4952 - val_loss: 2.4272 - val_accuracy: 0.3571\n",
      "Epoch 28/100\n",
      "14/14 [==============================] - 36s 3s/step - loss: 1.7400 - accuracy: 0.5143 - val_loss: 3.1295 - val_accuracy: 0.2286\n",
      "Epoch 29/100\n",
      "14/14 [==============================] - 36s 3s/step - loss: 1.7737 - accuracy: 0.4952 - val_loss: 3.0789 - val_accuracy: 0.3286\n",
      "Epoch 30/100\n",
      "14/14 [==============================] - 36s 3s/step - loss: 2.0792 - accuracy: 0.4952 - val_loss: 2.8300 - val_accuracy: 0.3857\n",
      "Epoch 31/100\n",
      "14/14 [==============================] - 38s 3s/step - loss: 2.0348 - accuracy: 0.5810 - val_loss: 2.3506 - val_accuracy: 0.3857\n",
      "Epoch 32/100\n",
      "14/14 [==============================] - 36s 3s/step - loss: 1.8156 - accuracy: 0.4762 - val_loss: 2.1927 - val_accuracy: 0.2857\n",
      "Epoch 33/100\n",
      "14/14 [==============================] - 37s 3s/step - loss: 1.6226 - accuracy: 0.5905 - val_loss: 2.3557 - val_accuracy: 0.3571\n",
      "Epoch 34/100\n",
      "14/14 [==============================] - 37s 3s/step - loss: 1.4142 - accuracy: 0.6000 - val_loss: 2.4428 - val_accuracy: 0.2286\n",
      "Epoch 35/100\n",
      "14/14 [==============================] - 37s 3s/step - loss: 1.6973 - accuracy: 0.5048 - val_loss: 2.2790 - val_accuracy: 0.3429\n",
      "Epoch 36/100\n",
      "14/14 [==============================] - 40s 3s/step - loss: 1.7289 - accuracy: 0.5179 - val_loss: 2.2730 - val_accuracy: 0.3429\n",
      "Epoch 37/100\n",
      "14/14 [==============================] - 37s 3s/step - loss: 1.5591 - accuracy: 0.5524 - val_loss: 2.2203 - val_accuracy: 0.3286\n",
      "Epoch 38/100\n",
      "14/14 [==============================] - 38s 3s/step - loss: 1.4975 - accuracy: 0.5524 - val_loss: 2.1768 - val_accuracy: 0.3857\n",
      "Epoch 39/100\n",
      "14/14 [==============================] - 38s 3s/step - loss: 1.6442 - accuracy: 0.5810 - val_loss: 2.9118 - val_accuracy: 0.3000\n",
      "Epoch 40/100\n",
      "14/14 [==============================] - 38s 3s/step - loss: 1.7094 - accuracy: 0.5524 - val_loss: 2.1770 - val_accuracy: 0.4429\n",
      "Epoch 41/100\n",
      "14/14 [==============================] - 36s 3s/step - loss: 1.4169 - accuracy: 0.6476 - val_loss: 2.3208 - val_accuracy: 0.2857\n",
      "Epoch 42/100\n",
      "14/14 [==============================] - 39s 3s/step - loss: 1.2764 - accuracy: 0.6696 - val_loss: 2.1487 - val_accuracy: 0.3714\n",
      "Epoch 43/100\n",
      "14/14 [==============================] - 37s 3s/step - loss: 1.3116 - accuracy: 0.6667 - val_loss: 2.1032 - val_accuracy: 0.4000\n",
      "Epoch 44/100\n",
      "14/14 [==============================] - 37s 3s/step - loss: 1.2084 - accuracy: 0.7143 - val_loss: 2.1168 - val_accuracy: 0.2857\n",
      "Epoch 45/100\n",
      "14/14 [==============================] - 38s 3s/step - loss: 1.2541 - accuracy: 0.6952 - val_loss: 2.1561 - val_accuracy: 0.4286\n",
      "Epoch 46/100\n",
      "14/14 [==============================] - 37s 3s/step - loss: 1.4278 - accuracy: 0.6286 - val_loss: 2.1328 - val_accuracy: 0.3000\n",
      "Epoch 47/100\n",
      "14/14 [==============================] - 38s 3s/step - loss: 1.1835 - accuracy: 0.7048 - val_loss: 2.2961 - val_accuracy: 0.3571\n",
      "Epoch 48/100\n",
      "14/14 [==============================] - 37s 3s/step - loss: 1.3616 - accuracy: 0.5714 - val_loss: 2.2877 - val_accuracy: 0.3857\n",
      "Epoch 49/100\n",
      "14/14 [==============================] - 37s 3s/step - loss: 1.1943 - accuracy: 0.6667 - val_loss: 2.5874 - val_accuracy: 0.2857\n",
      "Epoch 50/100\n",
      "14/14 [==============================] - 39s 3s/step - loss: 1.5227 - accuracy: 0.5238 - val_loss: 2.8433 - val_accuracy: 0.2857\n",
      "Epoch 51/100\n",
      "14/14 [==============================] - 37s 3s/step - loss: 1.4625 - accuracy: 0.6476 - val_loss: 2.7987 - val_accuracy: 0.3571\n",
      "Epoch 52/100\n",
      "14/14 [==============================] - 38s 3s/step - loss: 1.3052 - accuracy: 0.6000 - val_loss: 2.1954 - val_accuracy: 0.3571\n",
      "Epoch 53/100\n",
      "14/14 [==============================] - 38s 3s/step - loss: 1.2518 - accuracy: 0.6667 - val_loss: 2.1519 - val_accuracy: 0.4143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x298365d6880>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_vgg16.fit(datagen.flow(x_train, y_train, batch_size=5),\n",
    "         steps_per_epoch=len(x_train) // 5, epochs=100,\n",
    "         batch_size = 32,\n",
    "         validation_data=datagen.flow(x_valid,y_valid),\n",
    "         callbacks=[earlyStopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masked Face Recognition MobileNet (MobileNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.mobilenet import MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mobilenet_1.00_224\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 112, 112, 32)      864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)      288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 112, 112, 64)      2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 113, 113, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 56, 56, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 56, 56, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 57, 57, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 28, 28, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 28, 28, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 29, 29, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 14, 14, 512)       131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 7, 7, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 7, 7, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 7, 7, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 7, 7, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "=================================================================\n",
      "Total params: 3,228,864\n",
      "Trainable params: 3,206,976\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mobilenet_model = MobileNet(weights = 'imagenet',\n",
    "                           include_top=False,\n",
    "                           input_shape=(224,224,3))\n",
    "mobilenet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in mobilenet_model.layers:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lw(bottom_model, num_classes):\n",
    "    top_model = bottom_model.output\n",
    "    top_model = GlobalAveragePooling2D()(top_model)\n",
    "    top_model = Dense(1024,activation='relu')(top_model)\n",
    "    top_model = Dense(1024,activation='relu')(top_model)\n",
    "    top_model = Dense(512,activation='relu')(top_model)\n",
    "    top_model = Dense(num_classes,activation='softmax')(top_model)\n",
    "    return top_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 112, 112, 32)      864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)      288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 112, 112, 64)      2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 113, 113, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 56, 56, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 56, 56, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 57, 57, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 28, 28, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 28, 28, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 29, 29, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 14, 14, 512)       131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 7, 7, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 7, 7, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 7, 7, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 7, 7, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 23)                11799     \n",
      "=================================================================\n",
      "Total params: 5,864,663\n",
      "Trainable params: 2,635,799\n",
      "Non-trainable params: 3,228,864\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "num_classes = 23\n",
    "FC_Head = lw(mobilenet_model, num_classes)\n",
    "mobilenet_model = Model(inputs = mobilenet_model.input, outputs = FC_Head)\n",
    "mobilenet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "earlyStopping = EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0,\n",
    "                              patience=10,\n",
    "                              verbose=1,\n",
    "                              mode='min',\n",
    "                              restore_best_weights = True)\n",
    "mobilenet_model.compile(optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "28/28 [==============================] - 9s 220ms/step - loss: 3.4391 - accuracy: 0.0917 - val_loss: 3.2593 - val_accuracy: 0.1000\n",
      "Epoch 2/100\n",
      "28/28 [==============================] - 5s 176ms/step - loss: 2.8405 - accuracy: 0.1560 - val_loss: 2.7703 - val_accuracy: 0.1714\n",
      "Epoch 3/100\n",
      "28/28 [==============================] - 5s 177ms/step - loss: 2.4430 - accuracy: 0.2477 - val_loss: 2.5191 - val_accuracy: 0.1429\n",
      "Epoch 4/100\n",
      "28/28 [==============================] - 5s 175ms/step - loss: 2.0446 - accuracy: 0.3578 - val_loss: 2.4730 - val_accuracy: 0.2143\n",
      "Epoch 5/100\n",
      "28/28 [==============================] - 5s 176ms/step - loss: 1.7850 - accuracy: 0.4587 - val_loss: 2.2933 - val_accuracy: 0.3000\n",
      "Epoch 6/100\n",
      "28/28 [==============================] - 5s 178ms/step - loss: 1.4695 - accuracy: 0.5046 - val_loss: 1.9060 - val_accuracy: 0.4000\n",
      "Epoch 7/100\n",
      "28/28 [==============================] - 5s 182ms/step - loss: 1.1717 - accuracy: 0.6147 - val_loss: 2.4592 - val_accuracy: 0.3286\n",
      "Epoch 8/100\n",
      "28/28 [==============================] - 5s 182ms/step - loss: 1.3042 - accuracy: 0.6330 - val_loss: 2.0353 - val_accuracy: 0.2571\n",
      "Epoch 9/100\n",
      "28/28 [==============================] - 5s 184ms/step - loss: 1.1929 - accuracy: 0.5688 - val_loss: 1.6866 - val_accuracy: 0.4429\n",
      "Epoch 10/100\n",
      "28/28 [==============================] - 5s 189ms/step - loss: 0.7482 - accuracy: 0.7248 - val_loss: 1.5094 - val_accuracy: 0.5429\n",
      "Epoch 11/100\n",
      "28/28 [==============================] - 5s 188ms/step - loss: 0.6731 - accuracy: 0.8165 - val_loss: 1.6972 - val_accuracy: 0.4143\n",
      "Epoch 12/100\n",
      "28/28 [==============================] - 5s 181ms/step - loss: 0.8057 - accuracy: 0.7248 - val_loss: 1.4572 - val_accuracy: 0.5286\n",
      "Epoch 13/100\n",
      "28/28 [==============================] - 6s 197ms/step - loss: 0.6235 - accuracy: 0.8257 - val_loss: 1.4654 - val_accuracy: 0.5714\n",
      "Epoch 14/100\n",
      "28/28 [==============================] - 5s 186ms/step - loss: 0.5370 - accuracy: 0.8257 - val_loss: 1.0258 - val_accuracy: 0.6286\n",
      "Epoch 15/100\n",
      "28/28 [==============================] - 5s 184ms/step - loss: 0.4432 - accuracy: 0.8532 - val_loss: 1.3752 - val_accuracy: 0.5143\n",
      "Epoch 16/100\n",
      "28/28 [==============================] - 5s 177ms/step - loss: 0.5257 - accuracy: 0.7798 - val_loss: 1.1648 - val_accuracy: 0.6714\n",
      "Epoch 17/100\n",
      "28/28 [==============================] - 5s 186ms/step - loss: 0.3815 - accuracy: 0.8991 - val_loss: 1.3686 - val_accuracy: 0.6286\n",
      "Epoch 18/100\n",
      "28/28 [==============================] - 5s 182ms/step - loss: 0.3605 - accuracy: 0.8991 - val_loss: 1.1353 - val_accuracy: 0.6571\n",
      "Epoch 19/100\n",
      "28/28 [==============================] - 5s 179ms/step - loss: 0.2831 - accuracy: 0.8991 - val_loss: 1.2897 - val_accuracy: 0.6714\n",
      "Epoch 20/100\n",
      "28/28 [==============================] - 5s 183ms/step - loss: 0.2314 - accuracy: 0.9450 - val_loss: 0.9036 - val_accuracy: 0.7143\n",
      "Epoch 21/100\n",
      "28/28 [==============================] - 5s 182ms/step - loss: 0.2023 - accuracy: 0.9083 - val_loss: 1.2735 - val_accuracy: 0.6714\n",
      "Epoch 22/100\n",
      "28/28 [==============================] - 5s 194ms/step - loss: 0.4659 - accuracy: 0.8807 - val_loss: 1.6811 - val_accuracy: 0.6143\n",
      "Epoch 23/100\n",
      "28/28 [==============================] - 5s 182ms/step - loss: 0.2787 - accuracy: 0.9358 - val_loss: 1.2983 - val_accuracy: 0.6714\n",
      "Epoch 24/100\n",
      "28/28 [==============================] - 5s 179ms/step - loss: 0.2448 - accuracy: 0.8991 - val_loss: 1.3337 - val_accuracy: 0.6571\n",
      "Epoch 25/100\n",
      "28/28 [==============================] - 5s 174ms/step - loss: 0.4418 - accuracy: 0.8807 - val_loss: 1.7965 - val_accuracy: 0.6143\n",
      "Epoch 26/100\n",
      "28/28 [==============================] - 5s 186ms/step - loss: 0.3659 - accuracy: 0.9083 - val_loss: 1.2427 - val_accuracy: 0.6286\n",
      "Epoch 27/100\n",
      "28/28 [==============================] - 5s 179ms/step - loss: 0.2526 - accuracy: 0.9083 - val_loss: 1.2895 - val_accuracy: 0.6714\n",
      "Epoch 28/100\n",
      "28/28 [==============================] - 5s 177ms/step - loss: 0.5419 - accuracy: 0.8532 - val_loss: 1.0749 - val_accuracy: 0.6571\n",
      "Epoch 29/100\n",
      "28/28 [==============================] - 5s 178ms/step - loss: 0.2067 - accuracy: 0.9266 - val_loss: 1.5418 - val_accuracy: 0.6143\n",
      "Epoch 30/100\n",
      "28/28 [==============================] - 5s 176ms/step - loss: 0.2476 - accuracy: 0.9083 - val_loss: 1.4998 - val_accuracy: 0.6000\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00030: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2180e959790>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobilenet_model.fit(datagen.flow(x_train, y_train, batch_size=4),\n",
    "         steps_per_epoch=len(x_train) // 4, epochs=100,\n",
    "         validation_data=(x_valid,y_valid),\n",
    "         callbacks=[earlyStopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 1s - loss: 1.2592 - accuracy: 0.6957\n",
      "Trained model, accuracy: 69.57%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "y_pred = mobilenet_model.predict(x_test)\n",
    "y_pred=np.argmax(y_pred,axis=1)\n",
    "cnf_metric = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(pd.DataFrame(cnf_metric),annot=True,cmap=\"YlGnBu\",fmt=\"g\")\n",
    "plt.ylabel('Actual Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "\n",
    "loss, acc = mobilenet_model.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"Trained model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mobilenet_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-c3fa1f31de77>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmobilenet_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'mobilenet_model' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred = mobilenet_model.predict(x_test[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
